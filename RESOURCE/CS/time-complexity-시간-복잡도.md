
# 시간 복잡도

함수의 실행 시간을 표현하는 것이다.  
주로 점근적 분석을 통해 실행 시간을 단순하게 표현하며 이 때 점근적 표기법으로 표현한다.

알고리즘의 시간 복잡도는 입력의 길이에 대한 함수로서 **알고리즘을 실행하는 데 걸리는 시간**을 나타낸다.  실행 시간은 입력의 길이에 대한 함수이며, 알고리즘이 실행되는 컴퓨터의 실제 실행 기간과는 무관하다.


## 영상 요약본

[유튜브 - 쉬운코드](https://www.youtube.com/watch?v=tTFoClBZutw)  

### 1. 시간복잡도(Time Complexity)의 개념

- **정의:** 알고리즘(함수)을 수행하는 데 필요한 **실행 시간**을 의미합니다.
    
- **측정 기준:** 컴퓨터의 성능에 따라 실제 실행 시간(초, 밀리초)은 달라질 수 있습니다. 따라서 객관적인 측정을 위해 실행 시간이 아닌 **명령어의 실행 횟수(Steps)** 를 기준으로 삼습니다.
    
- **계산의 단순화:**
    
    - 모든 라인의 실행 비용을 상수로 가정하고 계산합니다.
        
    - 입력 크기($N$)가 작을 때는 실행 시간의 차이가 크지 않으므로, $N$이 무한대로 커질 때(점근적 분석) 실행 시간이 어떻게 변하는지에 집중합니다.
        

### 2. 점근적 분석 (Asymptotic Analysis)

입력 크기 $N$이 무한대로 증가할 때, 실행 시간 함수의 추세를 분석하는 방법입니다.

- **핵심 규칙:**
    
    1. **최고차항만 남긴다:** $N$이 커질수록 최고차항의 영향력이 절대적이므로, 낮은 차수의 항은 무시합니다. (예: $2N^2 + 3N + 1 \rightarrow N^2$)
        
    2. **계수는 무시한다:** 최고차항의 계수도 무시합니다. (예: $2N^2 \rightarrow N^2$)
        

### 3. 점근적 표기법 (Asymptotic Notation)

시간복잡도를 표현하는 3가지 주요 표기법입니다.

- **Big-O ($O$, 빅오): 상한선 (Upper Bound)**
    
    - "아무리 오래 걸려도 이 정도 시간보다는 덜 걸린다"는 최악의 경우를 표현할 때 주로 사용합니다.
        
    - 예: $O(N)$
        
- **Big-Omega ($\Omega$, 빅오메가): 하한선 (Lower Bound)**
    
    - "아무리 빨라도 이 정도 시간은 걸린다"는 최선의 경우를 표현할 때 사용합니다.
        
    - 예: $\Omega(1)$
        
- **Big-Theta ($\Theta$, 빅세타): 타이트한 경계 (Tight Bound)**
    
    - 상한선($O$)과 하한선($\Omega$)이 같을 때 사용합니다. 즉, 가장 정확한 표기입니다.
        
    - 예: $\Theta(N)$
        

### 4. 케이스별 분석 (Case Analysis)

알고리즘은 입력 데이터의 상태에 따라 실행 시간이 달라질 수 있습니다.

- **Best Case (최선의 경우):** 찾으려는 데이터가 맨 앞에 있는 경우 등. 가장 빠르게 실행되는 상황.
    
- **Worst Case (최악의 경우):** 찾으려는 데이터가 맨 뒤에 있거나 아예 없는 경우. 가장 느리게 실행되는 상황.
    
- **Average Case (평균적인 경우):** 일반적인 실행 상황.
    

### 5. 주요 시간복잡도 예제 및 분석

#### 1) 선형 탐색 (Linear Search)

- 배열의 앞에서부터 하나씩 확인하는 방식.
    
- **Best Case:** 맨 처음에 찾음 $\rightarrow \Omega(1)$ (상수 시간)
    
- **Worst Case:** 맨 뒤에 있거나 없음 $\rightarrow O(N)$ ($N$번 확인)
    
- **표기:** 상한과 하한이 다르므로 주로 **$O(N)$**으로 표기하여 "최악의 경우 $N$에 비례한다"고 말합니다.
    

#### 2) 이진 탐색 (Binary Search)

- **조건:** 데이터가 이미 **정렬**되어 있어야 함.
    
- **방식:** 중간값과 비교하여 탐색 범위를 절반씩 줄여나가는 방식.
    
- **분석:**
    
    - 한 번 비교할 때마다 남은 데이터가 절반($1/2$)으로 줄어듭니다.
        
    - 입력 크기가 $N$일 때, $k$번 시행 후 데이터가 1개가 된다면 $N \times (1/2)^k = 1$이 됩니다.
        
    - 이를 정리하면 $2^k = N$이 되고, 양변에 로그를 취하면 $k = \log_2 N$이 됩니다.
        
- **결과:** **$O(\log N)$** (로그 시간)
    

#### 3) 이중 반복문 (Nested Loop)

- 반복문 안에 반복문이 있는 경우.
    
- 바깥쪽 루프가 $N$번, 안쪽 루프가 $N$번 돌면 총 $N \times N$번 실행됩니다.
    
- **결과:** **$O(N^2)$** (이차 시간)
    

#### 4) 독립된 두 개의 반복문

- 입력 $A$($N$개)를 도는 루프와 입력 $B$($M$개)를 도는 루프가 따로 있는 경우.
    
- 두 입력 크기 중 더 큰 것에 영향을 받으므로 $O(N + M)$ 또는 $O(\max(N, M))$으로 표현합니다.
    

---

### 6. 속도 비교 (빠른 순서 $\rightarrow$ 느린 순서)

오른쪽으로 갈수록 성능이 안 좋은(느린) 알고리즘입니다.

$$O(1) < O(\log N) < O(N) < O(N \log N) < O(N^2) < O(2^N) < O(N!)$$

- $O(1)$: 입력 크기에 상관없이 일정한 속도 (상수 시간). 가장 빠름.
    
- $O(\log N)$: 이진 탐색 등. 매우 빠름.
    
- $O(N)$: 선형 탐색 등. 입력 크기에 비례.
    
- $O(N \log N)$: 효율적인 정렬 알고리즘(Merge Sort 등)에서 주로 나타남.
    
- $O(N^2)$: 이중 루프. 데이터가 많아지면 느려짐.
    
- $O(2^N)$: 피보나치 수열 재귀 등. 데이터가 조금만 늘어도 매우 느려짐.
    

---

### 7. 왜 주로 Big-O 표기법을 쓸까?

영상에서는 개발자들이 $\Theta$(세타)나 $\Omega$(오메가)보다 **$O$(빅오)를 주로 사용하는 이유**를 다음과 같이 설명합니다.

1. **최악의 상황 대비:** 일반적으로 "최소 얼마 걸린다"보다는 "아무리 늦어도 언제까지는 끝난다(상한선)" 는 정보가 자원 할당이나 계획 수립에 더 유용합니다.
    
2. **편의성:** 상한선만 계산하는 것이 더 쉽고, 타이트한 바운드($\Theta$)를 증명하기 까다로운 경우가 많습니다.
    
3. **통용성:** 업계 표준처럼 굳어져서 다들 그렇게 쓰기 때문입니다.
    

요약하자면, 시간복잡도는 알고리즘의 효율성을 평가하는 척도이며, 주로 최악의 경우를 가정한 Big-O($O$) 표기법을 사용하여 $N$의 증가에 따른 성능 저하를 예측합니다.

# 출처

[유튜브 - 쉬운코드](https://www.youtube.com/watch?v=tTFoClBZutw)  
